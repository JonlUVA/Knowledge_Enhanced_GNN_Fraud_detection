{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyMON33qTMYWChrgSXCTRp4e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NxyV7UYslMA1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e7bd75c-a9ae-46b0-d526-a7ec8d3f4ea9","executionInfo":{"status":"ok","timestamp":1719224413061,"user_tz":-120,"elapsed":2622032,"user":{"displayName":"Jonathon Longden","userId":"15152484921944324310"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","Epoch: 010, Loss: 0.0266\n","Best current threshold: 0.0 Best F1 score: 0.002464221182472929  number of fraud:  3209.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00   2598056\n","         1.0       0.00      1.00      0.00      3209\n","\n","    accuracy                           0.00   2601265\n","   macro avg       0.00      0.50      0.00   2601265\n","weighted avg       0.00      0.00      0.00   2601265\n","\n","new best model\n","final best f1: 0.002464221182472929, best threshold: 0.0\n","validation optimised test results:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00   2598314\n","         1.0       0.00      1.00      0.00      2951\n","\n","    accuracy                           0.00   2601265\n","   macro avg       0.00      0.50      0.00   2601265\n","weighted avg       0.00      0.00      0.00   2601265\n","\n"]}],"source":["# Mounting Google Colab drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Imports\n","import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, recall_score, precision_score\n","from joblib import Parallel, delayed\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pickle\n","\n","# Installing required packages\n","!pip install torch-geometric\n","\n","import torch_geometric.transforms as T\n","from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n","from torch_geometric.data import HeteroData\n","from torch.autograd import Variable\n","\n","# Change directory to location\n","loc = \"/content/drive/MyDrive/KE_GNN/\"\n","os.chdir(loc)\n","os.getcwd()\n","\n","#number of epochs\n","epoch_n = 211\n","#sample number\n","run_number = 1\n","\n","def move_to_device(obj, device):\n","  '''\n","  moves a dictionary to device (if needed)\n","  '''\n","  if isinstance(obj, torch.Tensor):\n","      return obj.to(device)\n","  elif isinstance(obj, dict):\n","      return {k: move_to_device(v, device) for k, v in obj.items()}\n","  elif isinstance(obj, list):\n","      return [move_to_device(i, device) for i in obj]\n","  elif isinstance(obj, tuple):\n","      return tuple(move_to_device(i, device) for i in obj)\n","  elif isinstance(obj, set):\n","      return {move_to_device(i, device) for i in obj}\n","  else:\n","      return obj\n","\n","# load train graph and clause dictionary\n","data_train = torch.load('{}Graph storage/train_graph.pt'.format(loc))\n","with open('{}Clause Storage/train_KE_location_large.pkl'.format(loc), 'rb') as handle:\n","    train_KE_location = pickle.load(handle)\n","\n","# load train graph and clause dictionary\n","data_valid = torch.load('{}Graph storage/valid_graph.pt'.format(loc))\n","with open('{}Clause Storage/valid_KE_location_large.pkl'.format(loc), 'rb') as handle:\n","    valid_KE_location = pickle.load(handle)\n","\n","# load train graph and clause dictionary\n","data_test = torch.load('{}Graph storage/test_graph.pt'.format(loc))\n","with open('{}Clause Storage/test_KE_location_large.pkl'.format(loc), 'rb') as handle:\n","    test_KE_location = pickle.load(handle)\n","\n","# load knowledge enhancement\n","with open('{}Clause Storage/Knowledge_enhancements_large.pkl'.format(loc), 'rb') as handle:\n","    KE_conditions = pickle.load(handle)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","\n","keys_keep = ['RULE1', 'RULE2', 'RULE3', 'RULE4', 'RULE5']\n","train_KE_location = subset_dict(train_KE_location, keys_keep)\n","valid_KE_location = subset_dict(valid_KE_location, keys_keep)\n","test_KE_location = subset_dict(test_KE_location, keys_keep)\n","KE_conditions = subset_dict(KE_conditions, keys_keep)\n","\n","def f1_finder(pred, true, max_val):\n","    '''\n","    Finds the best threshold for maximizing the F1-score of a binary classifier.\n","\n","    Args:\n","        pred: Predicted values for the positive class.\n","        true: True binary labels.\n","        max_val: The maximum threshold value to consider.\n","\n","    Returns:\n","        The threshold that maximizes the F1-score.\n","    '''\n","    thresholds = np.linspace(0, max_val, num=200, endpoint=True)\n","\n","    def compute_f1(threshold):\n","        return f1_score(true, (pred > threshold).astype(int), zero_division=0.0)\n","\n","    f1_scores = Parallel(n_jobs=-1)(delayed(compute_f1)(x) for x in thresholds)\n","\n","    best_index = np.argmax(f1_scores)\n","    best_x = thresholds[best_index]\n","    return best_x\n","\n","# Using the Heterogeneous Convolution Wrapper\n","class HeteroGNN(torch.nn.Module):\n","    def __init__(self, hidden_channels, out_channels, num_layers1, num_layers2, KE, KE_dictionary, conditions):\n","        super().__init__()\n","\n","\n","        self.convs1 = torch.nn.ModuleList()\n","        for _ in range(num_layers1):\n","          # first convolution networks\n","            conv = HeteroConv({\n","              ('user', 'owns', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              ('card', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('location', 'rev_happend_at', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought_from', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'rev_bought_from', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'bought_in', 'location'): SAGEConv((-1, -1), hidden_channels),\n","              ('card', 'bought_with', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'rev_bought_with', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              }, aggr='sum')\n","            self.convs1.append(conv)\n","\n","        self.convs2 = torch.nn.ModuleList()\n","        for _ in range(num_layers2):\n","          # second convolution networks. focusing purely on transactions\n","            conv = HeteroConv({\n","               ('card', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_bought', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'bought_in', 'location'): SAGEConv((-1, -1), hidden_channels),\n","              ('location', 'rev_bought_in', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              }, aggr='sum')\n","            self.convs2.append(conv)\n","        # creating parameter dictionary for clauses\n","        self.params = nn.ParameterDict()\n","        for k, v in KE_dictionary.items():\n","          self.params[k] = nn.Parameter(torch.tensor([1], dtype=torch.float32))\n","\n","\n","        self.lin = Linear(hidden_channels, out_channels)\n","    def forward(self, x_dict, edge_index_dict, KE, KE_dictionary, conditions):\n","      # first convolution layer\n","      for conv in self.convs1:\n","        x_dict = conv(x_dict, edge_index_dict)\n","        x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n","      # second convolution layer\n","      for conv in self.convs2:\n","        x_dict = conv(x_dict, edge_index_dict)\n","        x_dict = {key: F.leaky_relu( x) for key, x in x_dict.items()}\n","      # linear layer\n","      no_KE_output = torch.sigmoid(self.lin(x_dict['transaction']))\n","      if KE:\n","            # creating copy of output, dictionary of clauses, outputs\n","            final_out = no_KE_output\n","            rule_outputs = []\n","            KE_output_dic = {}\n","            for k, v in conditions.items():\n","              #only record if there is atleast one transaction which adheres to the clause\n","                if torch.sum(v) > 0:\n","                    KE_output_dic[k] = ((self.params[k]-1) * v) * final_out\n","                    rule_outputs.append((k,self.params[k].item()))\n","                    final_out = torch.clamp(KE_output_dic[k] + final_out, min = 0, max= 1)\n","            return final_out, rule_outputs\n","      else:\n","          return no_KE_output\n","\n","# Creating model\n","KE_TF = True\n","model = HeteroGNN(hidden_channels=168, out_channels=1, num_layers1=2,\n","              num_layers2 =2, KE = KE_TF, KE_dictionary = KE_conditions,\n","              conditions = train_KE_location)\n","\n","\n","\n","\n","# move to device (if needed)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","data_test = data_test.to(device)\n","data_train = data_train.to(device)\n","data_valid.to(device)\n","# move dictionaries to device (if needed)\n","KE_conditions = move_to_device(KE_conditions, device)\n","train_KE_location = move_to_device(train_KE_location, device)\n","valid_KE_location = move_to_device(valid_KE_location, device)\n","test_KE_location = move_to_device(test_KE_location, device)\n","\n","# initializing model\n","with torch.no_grad():\n","    out = model(data_train.x_dict, data_train.edge_index_dict,\n","                KE = KE_TF, KE_dictionary = KE_conditions, conditions = train_KE_location)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.BCELoss()\n","\n","\n","def inductive_train():\n","  '''\n","      Performs a single training step for the model.\n","    Returns:\n","        loss: The computed loss for the current training step.\n","        rule_outputs: The output from clause weights\n","  '''\n","  model.train()\n","  optimizer.zero_grad()  # Clear gradients\n","  out, weights = model(data_train.x_dict, data_train.edge_index_dict,\n","              KE = KE_TF, KE_dictionary = KE_conditions, conditions = train_KE_location)  # Perform a single forward pass\n","  loss = criterion(out, data_train['transaction'].y)  # Compute the loss solely based on the training nodes\n","  loss.backward()\n","  optimizer.step()\n","  return loss, weights\n","\n","\n","def test():\n","  '''\n","    Test the model on the validation set.\n","\n","    Returns:\n","        The predicted and true labels for the validation set.\n","  '''\n","  model.eval()\n","  out, _ = model(data_valid.x_dict, data_valid.edge_index_dict,\n","              KE = KE_TF, KE_dictionary = KE_conditions, conditions = valid_KE_location)\n","  pred = out.detach().cpu().numpy()\n","  true_labels = data_valid['transaction'].y.cpu()\n","  return pred, true_labels.numpy()\n","\n","\n","\n","# training loop, saving best model as it continues to train to ensure that the best model is selected for predictions\n","f1_best = 0\n","f1 = 0\n","best_model_state = None\n","measures = []\n","weights = []\n","for epoch in range(1, epoch_n):\n","    print(epoch)\n","    weights_raw = []\n","    loss, weights_raw = inductive_train()\n","    weights.append(weights_raw.copy())\n","    if epoch % 10 == 0:\n","        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n","        pred, truess = test()\n","\n","        threshold = f1_finder(pred, truess, 1.0)\n","        predss_thres = (pred > threshold).astype(int)\n","\n","        f1 = f1_score(truess, predss_thres, zero_division = 0.0)\n","        recall = recall_score(truess, predss_thres, zero_division = 0.0)\n","        prc = precision_score(truess, predss_thres, zero_division = 0.0)\n","\n","        print('Best current threshold:', threshold, 'Best F1 score:', f1, ' number of fraud: ', np.sum(truess))\n","        print(classification_report(truess, predss_thres))\n","        measures.append([epoch,loss,f1,threshold, recall,prc])\n","        if f1 > f1_best:\n","            print('new best model')\n","            f1_best = f1  # Update the best F1 score\n","            best_thresh = threshold\n","            #save best current model\n","            torch.save({'epoch': epoch,'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss, }, '{}/Main Experiment/model_storage/KeGCN5_{}.pt'.format(loc,run_number))\n","print('final best f1: {}, best threshold: {}'.format(f1_best, best_thresh))\n","\n","\n","#extracting weight data\n","extracted_data = []\n","# Extract tensor values from the list\n","for rule_set in weights:\n","    row = {rule: param for rule, param in rule_set}\n","    extracted_data.append(row)\n","\n","# Dataframe containing extracted weights\n","df3 = pd.DataFrame(extracted_data)\n","\n","# re-create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = HeteroGNN(hidden_channels=168, out_channels=1, num_layers1=2,\n","                num_layers2 = 2, KE = KE_TF, KE_dictionary = KE_conditions,\n","                conditions = test_KE_location)\n","\n","\n","# move to device if needed\n","model.to(device)\n","data_train.to(device)\n","KE_conditions = move_to_device(KE_conditions, device)\n","train_KE_location = move_to_device(train_KE_location, device)\n","valid_KE_location = move_to_device(valid_KE_location, device)\n","\n","\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#load best performing model\n","checkpoint = torch.load('{}/Main Experiment/model_storage/KeGCN5_{}.pt'.format(loc,run_number))\n","\n","# Load the model and optimizer state dictionaries\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","test_measure = []\n","out,_ = model(data_test.x_dict, data_test.edge_index_dict, KE_TF, KE_conditions, test_KE_location)\n","pred = out.detach().cpu().numpy()\n","true_labels = data_test['transaction'].y.cpu()\n","\n","pred = out.detach().cpu().numpy()\n","true_labels = data_test['transaction'].y.cpu()\n","# predictions using the best threshold found in the best model\n","predss_thres = (pred > best_thresh).astype(int)\n","best_validation_threshold = best_thresh.copy()\n","# f1 score from the test\n","f1_val_thresh_test_set = f1_score(true_labels, predss_thres)\n","print('validation optimised test results:')\n","print(classification_report(true_labels, predss_thres))\n","recall_val_thres_test = recall_score(true_labels, predss_thres)\n","precision_val_thres_test = precision_score(true_labels, predss_thres)\n","\n","# test optimised results\n","threshold = f1_finder(pred, true_labels, 1.0)\n","test_optimised_prediction = (pred > threshold).astype(int)\n","\n","f1_test_optimised = f1_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","recall_test_optimised = recall_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","precision_test_optimised = precision_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","\n","test_measure.append([f1_val_thresh_test_set, best_validation_threshold, recall_val_thres_test, precision_val_thres_test,\n","                   f1_test_optimised, threshold, recall_test_optimised, precision_test_optimised])\n","\n","# final model results\n","df2 = pd.DataFrame(test_measure, columns = ['test_train_thresh_f1', 'test_train_thresh', 'test_train_recall', 'test_train_precision',\n","                                          'test_f1','test_thresh', 'test_recall', 'test_precision'])\n","#training results\n","df1 = pd.DataFrame(measures, columns=['epoch', 'training loss', 'optimised_f1','threshold', 'recall', 'precision'])\n","\n","# save model\n","df1.to_csv('{}/Main Experiment/output/KeGCN_5_clause/KE_GCN_training_results_{}.csv'.format(loc, run_number))\n","df2.to_csv('{}/Main Experiment/output/KeGCN_5_clause/KE_GCN_test_results_{}.csv'.format(loc, run_number))\n","df3.to_csv('{}/Main Experiment/output/KeGCN_5_clause/KE_GCN_train_weights_{}.csv'.format(loc, run_number))\n","\n","\n","\n"]},{"cell_type":"code","source":["#extracting weight data\n","extracted_data = []\n","# Extract tensor values from the list\n","for rule_set in weights:\n","    row = {rule: param for rule, param in rule_set}\n","    extracted_data.append(row)\n","\n","# Dataframe containing extracted weights\n","df3 = pd.DataFrame(extracted_data)\n","\n","# re-create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = HeteroGNN(hidden_channels=168, out_channels=1, num_layers1=2,\n","                num_layers2 = 2, KE = KE_TF, KE_dictionary = KE_conditions,\n","                conditions = test_KE_location)\n","\n","\n","# move to device if needed\n","model.to(device)\n","data_train.to(device)\n","KE_conditions = move_to_device(KE_conditions, device)\n","train_KE_location = move_to_device(train_KE_location, device)\n","valid_KE_location = move_to_device(valid_KE_location, device)\n","\n","\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#load best performing model\n","checkpoint = torch.load('{}/model_storage/KeGCN10_{}.pt'.format(loc,run_number))\n","\n","# Load the model and optimizer state dictionaries\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","out,_ = model(data_test.x_dict, data_test.edge_index_dict, KE_TF, KE_conditions, test_KE_location)\n","pred = out.detach().cpu().numpy()\n","true_labels = data_test['transaction'].y.cpu()\n","\n","# predictions using the best threshold found in the best model\n","predss_thres = (pred > best_thresh).astype(int)\n","best_validation_threshold = best_thresh.copy()\n","# f1 score from the test\n","f1_val_thresh_test_set = f1_score(true_labels, predss_thres)\n","print('validation optimised test results:')\n","print(classification_report(true_labels, predss_thres))\n","recall_val_thres_test = recall_score(true_labels, predss_thres)\n","precision_val_thres_test = precision_score(true_labels, predss_thres)\n","\n","# test optimised results\n","threshold = f1_finder(pred, true_labels, 1.0)\n","test_optimised_prediction = (pred > threshold).astype(int)\n","\n","f1_test_optimised = f1_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","recall_test_optimised = recall_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","precision_test_optimised = precision_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","\n","test_measure.append([f1_val_thresh_test_set, best_validation_threshold, recall_val_thres_test, precision_val_thres_test,\n","                   f1_test_optimised, threshold, recall_test_optimised, precision_test_optimised])\n","\n","# final model results\n","df2 = pd.DataFrame(test_measure, columns = ['test_train_thresh_f1', 'test_train_thresh', 'test_train_recall', 'test_train_precision',\n","                                          'test_f1','test_thresh', 'test_recall', 'test_precision'])\n","#training results\n","df1 = pd.DataFrame(measures, columns=['epoch', 'training loss', 'optimised_f1','threshold', 'recall', 'precision'])\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":654},"id":"Pg1avC0AVdXW","executionInfo":{"status":"error","timestamp":1719217588461,"user_tz":-120,"elapsed":123976,"user":{"displayName":"Jonathon Longden","userId":"15152484921944324310"}},"outputId":"528b2744-630f-4210-c573-34228f5d654a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["validation optimised test results:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00   2598314\n","         1.0       0.00      1.00      0.00      2951\n","\n","    accuracy                           0.00   2601265\n","   macro avg       0.00      0.50      0.00   2601265\n","weighted avg       0.00      0.00      0.00   2601265\n","\n"]},{"output_type":"error","ename":"OSError","evalue":"Cannot save file into a non-existent directory: 'KE_GCN/KeGCN_10_clause'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-d570e0c328c2>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# save mocel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KE_GCN/KeGCN_10_clause/KE_GCN_training_results_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KE_GCN/KeGCN_10_clause/KE_GCN_test_results_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KE_GCN/KeGCN_10_clause/KE_GCN_train_weights_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3770\u001b[0m         )\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3773\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3774\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'KE_GCN/KeGCN_10_clause'"]}]},{"cell_type":"code","source":["\n","\n","\n","\n"],"metadata":{"id":"MiQH6rIwW9v9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save({'epoch': epoch,'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss, }, '{}/model_storage/KeGCN10_{}.pt'.format(loc,run_number))"],"metadata":{"id":"jey2uLq_VIvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loc = \"/content/drive/MyDrive/KE_GNN/Main Experiment\"\n"],"metadata":{"id":"FIMwqo5ZVJdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3T12fpOcVWVT"},"execution_count":null,"outputs":[]}]}