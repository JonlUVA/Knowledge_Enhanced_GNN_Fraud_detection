{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyPT4fE/AY0pBQfoKADoTGYl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NxyV7UYslMA1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d372fe17-9402-4dfe-d8b3-04b473f81ee9","executionInfo":{"status":"ok","timestamp":1719228112414,"user_tz":-120,"elapsed":2687119,"user":{"displayName":"Jonathon Longden","userId":"15152484921944324310"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Collecting aiohttp (from torch-geometric)\n","  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n","  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m129.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n","  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->torch-geometric)\n","  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->torch-geometric)\n","  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torch-geometric\n","Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.0.5 torch-geometric-2.5.3 yarl-1.9.4\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","Epoch: 010, Loss: 0.0282\n","Best current threshold: 0.0 Best F1 score: 0.002464221182472929  number of fraud:  3209.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00   2598056\n","         1.0       0.00      1.00      0.00      3209\n","\n","    accuracy                           0.00   2601265\n","   macro avg       0.00      0.50      0.00   2601265\n","weighted avg       0.00      0.00      0.00   2601265\n","\n","new best model\n","final best f1: 0.002464221182472929, best threshold: 0.0\n","validation optimised test results:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00   2598314\n","         1.0       0.00      1.00      0.00      2951\n","\n","    accuracy                           0.00   2601265\n","   macro avg       0.00      0.50      0.00   2601265\n","weighted avg       0.00      0.00      0.00   2601265\n","\n"]}],"source":["# Mounting Google Colab drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Imports\n","import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, recall_score, precision_score\n","from joblib import Parallel, delayed\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pickle\n","\n","# Installing required packages\n","!pip install torch-geometric\n","\n","import torch_geometric.transforms as T\n","from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n","from torch_geometric.data import HeteroData\n","from torch.autograd import Variable\n","\n","# Change directory to location\n","loc = \"/content/drive/MyDrive/KE_GNN/\"\n","os.chdir(loc)\n","os.getcwd()\n","\n","#number of epochs\n","epoch_n = 11\n","#sample number\n","run_number = 1\n","\n","def move_to_device(obj, device):\n","  '''\n","  moves a dictionary to device (if needed)\n","  '''\n","  if isinstance(obj, torch.Tensor):\n","      return obj.to(device)\n","  elif isinstance(obj, dict):\n","      return {k: move_to_device(v, device) for k, v in obj.items()}\n","  elif isinstance(obj, list):\n","      return [move_to_device(i, device) for i in obj]\n","  elif isinstance(obj, tuple):\n","      return tuple(move_to_device(i, device) for i in obj)\n","  elif isinstance(obj, set):\n","      return {move_to_device(i, device) for i in obj}\n","  else:\n","      return obj\n","\n","# loading empty dictionaries in place of KE to reduce model modifications\n","# load train graph and clause dictionary\n","data_train = torch.load('{}Graph storage/post_hoc_train_graph.pt'.format(loc))\n","train_KE_location = {}\n","\n","# load train graph and clause dictionary\n","data_valid = torch.load('{}Graph storage/post_hoc_valid_graph.pt'.format(loc))\n","valid_KE_location = {}\n","\n","# load train graph and clause dictionary\n","data_test = torch.load('{}Graph storage/post_hoc_test_graph.pt'.format(loc))\n","test_KE_location = {}\n","\n","# load knowledge enhancement\n","KE_conditions = {}\n","\n","# set up GPU (if needed)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","def f1_finder(pred, true, max_val):\n","    '''\n","    Finds the best threshold for maximizing the F1-score of a binary classifier.\n","\n","    Args:\n","        pred: Predicted values for the positive class.\n","        true: True binary labels.\n","        max_val: The maximum threshold value to consider.\n","\n","    Returns:\n","        The threshold that maximizes the F1-score.\n","    '''\n","    thresholds = np.linspace(0, max_val, num=200, endpoint=True)\n","\n","    def compute_f1(threshold):\n","        return f1_score(true, (pred > threshold).astype(int), zero_division=0.0)\n","\n","    f1_scores = Parallel(n_jobs=-1)(delayed(compute_f1)(x) for x in thresholds)\n","\n","    best_index = np.argmax(f1_scores)\n","    best_x = thresholds[best_index]\n","    return best_x\n","\n","# Using the Heterogeneous Convolution Wrapper\n","class HeteroGNN(torch.nn.Module):\n","    def __init__(self, hidden_channels, out_channels, num_layers1, num_layers2, KE, KE_dictionary, conditions):\n","        super().__init__()\n","\n","\n","        self.convs1 = torch.nn.ModuleList()\n","        for _ in range(num_layers1):\n","          # first convolution networks\n","            conv = HeteroConv({\n","              ('user', 'owns', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              ('card', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('location', 'rev_happend_at', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought_from', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'rev_bought_from', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'bought_in', 'location'): SAGEConv((-1, -1), hidden_channels),\n","              ('card', 'bought_with', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'rev_bought_with', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              }, aggr='sum')\n","            self.convs1.append(conv)\n","\n","        self.convs2 = torch.nn.ModuleList()\n","        for _ in range(num_layers2):\n","          # second convolution networks. focusing purely on transactions\n","            conv = HeteroConv({\n","               ('card', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'card'): SAGEConv((-1, -1), hidden_channels),\n","              ('merchant', 'transfer', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_transfer', 'merchant'): SAGEConv((-1, -1), hidden_channels),\n","              ('user', 'bought', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'rev_bought', 'user'): SAGEConv((-1, -1), hidden_channels),\n","              ('transaction', 'bought_in', 'location'): SAGEConv((-1, -1), hidden_channels),\n","              ('location', 'rev_bought_in', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n","              }, aggr='sum')\n","            self.convs2.append(conv)\n","        # creating parameter dictionary for clauses\n","        self.params = nn.ParameterDict()\n","        for k, v in KE_dictionary.items():\n","          self.params[k] = nn.Parameter(torch.tensor([1], dtype=torch.float32))\n","\n","\n","        self.lin = Linear(hidden_channels, out_channels)\n","    def forward(self, x_dict, edge_index_dict, KE, KE_dictionary, conditions):\n","      # first convolution layer\n","      for conv in self.convs1:\n","        x_dict = conv(x_dict, edge_index_dict)\n","        x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n","      # second convolution layer\n","      for conv in self.convs2:\n","        x_dict = conv(x_dict, edge_index_dict)\n","        x_dict = {key: F.leaky_relu( x) for key, x in x_dict.items()}\n","      # linear layer\n","      no_KE_output = torch.sigmoid(self.lin(x_dict['transaction']))\n","      if KE:\n","            # creating copy of output, dictionary of clauses, outputs\n","            final_out = no_KE_output\n","            rule_outputs = []\n","            KE_output_dic = {}\n","            for k, v in conditions.items():\n","              #only record if there is atleast one transaction which adheres to the clause\n","                if torch.sum(v) > 0:\n","                    KE_output_dic[k] = ((self.params[k]-1) * v) * final_out\n","                    rule_outputs.append((k,self.params[k].item()))\n","                    final_out = torch.clamp(KE_output_dic[k] + final_out, min = 0, max= 1)\n","            return final_out, rule_outputs\n","      else:\n","          return no_KE_output, []\n","\n","# Creating model\n","# setting false as no KE\n","KE_TF = False\n","model = HeteroGNN(hidden_channels=168, out_channels=1, num_layers1=2,\n","              num_layers2 =2, KE = KE_TF, KE_dictionary = KE_conditions,\n","              conditions = train_KE_location)\n","\n","\n","\n","\n","# move to device (if needed)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","data_test = data_test.to(device)\n","data_train = data_train.to(device)\n","data_valid.to(device)\n","# move dictionaries to device (if needed)\n","KE_conditions = move_to_device(KE_conditions, device)\n","train_KE_location = move_to_device(train_KE_location, device)\n","valid_KE_location = move_to_device(valid_KE_location, device)\n","test_KE_location = move_to_device(test_KE_location, device)\n","\n","# initializing model\n","with torch.no_grad():\n","    out = model(data_train.x_dict, data_train.edge_index_dict,\n","                KE = KE_TF, KE_dictionary = KE_conditions, conditions = train_KE_location)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.BCELoss()\n","\n","\n","def inductive_train():\n","  '''\n","      Performs a single training step for the model.\n","    Returns:\n","        loss: The computed loss for the current training step.\n","        rule_outputs: The output from clause weights\n","  '''\n","  model.train()\n","  optimizer.zero_grad()  # Clear gradients\n","  out, weights = model(data_train.x_dict, data_train.edge_index_dict,\n","              KE = KE_TF, KE_dictionary = KE_conditions, conditions = train_KE_location)  # Perform a single forward pass\n","  loss = criterion(out, data_train['transaction'].y)  # Compute the loss solely based on the training nodes\n","  loss.backward()\n","  optimizer.step()\n","  return loss, weights\n","\n","\n","def test():\n","  '''\n","    Test the model on the validation set.\n","\n","    Returns:\n","        The predicted and true labels for the validation set.\n","  '''\n","  model.eval()\n","  out, _ = model(data_valid.x_dict, data_valid.edge_index_dict,\n","              KE = KE_TF, KE_dictionary = KE_conditions, conditions = valid_KE_location)\n","  pred = out.detach().cpu().numpy()\n","  true_labels = data_valid['transaction'].y.cpu()\n","  return pred, true_labels.numpy()\n","\n","\n","\n","# training loop, saving best model as it continues to train to ensure that the best model is selected for predictions\n","f1_best = 0\n","f1 = 0\n","best_model_state = None\n","measures = []\n","weights = []\n","for epoch in range(1, epoch_n):\n","    print(epoch)\n","    weights_raw = []\n","    loss, weights_raw = inductive_train()\n","    weights.append(weights_raw.copy())\n","    if epoch % 10 == 0:\n","        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n","        pred, truess = test()\n","\n","        threshold = f1_finder(pred, truess, 1.0)\n","        predss_thres = (pred > threshold).astype(int)\n","\n","        f1 = f1_score(truess, predss_thres, zero_division = 0.0)\n","        recall = recall_score(truess, predss_thres, zero_division = 0.0)\n","        prc = precision_score(truess, predss_thres, zero_division = 0.0)\n","\n","        print('Best current threshold:', threshold, 'Best F1 score:', f1, ' number of fraud: ', np.sum(truess))\n","        print(classification_report(truess, predss_thres))\n","        measures.append([epoch,loss,f1,threshold, recall,prc])\n","        if f1 > f1_best:\n","            print('new best model')\n","            f1_best = f1  # Update the best F1 score\n","            best_thresh = threshold\n","            #save best current model\n","            torch.save({'epoch': epoch,'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss, }, '{}/Post Hoc/model_storage/PH_GCN_{}.pt'.format(loc,run_number))\n","print('final best f1: {}, best threshold: {}'.format(f1_best, best_thresh))\n","\n","\n","# re-create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = HeteroGNN(hidden_channels=168, out_channels=1, num_layers1=2,\n","                num_layers2 = 2, KE = KE_TF, KE_dictionary = KE_conditions,\n","                conditions = test_KE_location)\n","\n","\n","# move to device if needed\n","model.to(device)\n","data_train.to(device)\n","KE_conditions = move_to_device(KE_conditions, device)\n","train_KE_location = move_to_device(train_KE_location, device)\n","valid_KE_location = move_to_device(valid_KE_location, device)\n","\n","\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#load best performing model\n","checkpoint = torch.load('{}/Post Hoc/model_storage/PH_GCN_{}.pt'.format(loc,run_number))\n","\n","# Load the model and optimizer state dictionaries\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","test_measure = []\n","out,_ = model(data_test.x_dict, data_test.edge_index_dict, KE_TF, KE_conditions, test_KE_location)\n","pred = out.detach().cpu().numpy()\n","true_labels = data_test['transaction'].y.cpu()\n","\n","pred = out.detach().cpu().numpy()\n","true_labels = data_test['transaction'].y.cpu()\n","# predictions using the best threshold found in the best model\n","predss_thres = (pred > best_thresh).astype(int)\n","best_validation_threshold = best_thresh.copy()\n","# f1 score from the test\n","f1_val_thresh_test_set = f1_score(true_labels, predss_thres)\n","print('validation optimised test results:')\n","print(classification_report(true_labels, predss_thres))\n","recall_val_thres_test = recall_score(true_labels, predss_thres)\n","precision_val_thres_test = precision_score(true_labels, predss_thres)\n","\n","# test optimised results\n","threshold = f1_finder(pred, true_labels, 1.0)\n","test_optimised_prediction = (pred > threshold).astype(int)\n","\n","f1_test_optimised = f1_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","recall_test_optimised = recall_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","precision_test_optimised = precision_score(true_labels, test_optimised_prediction, zero_division = 0.0)\n","\n","test_measure.append([f1_val_thresh_test_set, best_validation_threshold, recall_val_thres_test, precision_val_thres_test,\n","                   f1_test_optimised, threshold, recall_test_optimised, precision_test_optimised])\n","\n","# final model results\n","df2 = pd.DataFrame(test_measure, columns = ['test_train_thresh_f1', 'test_train_thresh', 'test_train_recall', 'test_train_precision',\n","                                          'test_f1','test_thresh', 'test_recall', 'test_precision'])\n","#training results\n","df1 = pd.DataFrame(measures, columns=['epoch', 'training loss', 'optimised_f1','threshold', 'recall', 'precision'])\n","\n","# save model\n","df1.to_csv('{}/Post Hoc/output/GCN/GCN_training_results_{}.csv'.format(loc, run_number))\n","df2.to_csv('{}/Post Hoc/output/GCN/GCN_test_results_{}.csv'.format(loc, run_number))\n","\n","\n","\n","\n"]}]}